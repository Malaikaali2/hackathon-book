---
sidebar_position: 31
---

# Glossary of Terms

## A

**Action Space**: The set of all possible actions that an agent can take in a reinforcement learning environment. In robotics, this typically includes motor commands, joint positions, velocities, or torques.

**Actuator**: A component of a robot that converts control signals into physical motion. Common types include servo motors, stepper motors, and pneumatic/hydraulic actuators.

**Adaptive Control**: A control method that adjusts its parameters in real-time based on changes in the system or environment to maintain optimal performance.

**Affordance**: In robotics and AI, the possibility of an action that an environment provides to an agent. For example, a handle affords grasping.

**AI Foundation Model**: Large-scale machine learning models trained on broad data that can be adapted to various downstream tasks, particularly important in VLA (Vision-Language-Action) systems.

**Algorithmic Fairness**: The principle that AI algorithms should not produce results that are biased against certain groups, particularly important in autonomous systems that interact with humans.

**Angular Velocity**: The rate of change of angular position of a rotating body, typically measured in radians per second, crucial for robot motion control.

**Anomaly Detection**: The identification of rare items, events, or observations that deviate significantly from the majority of the data, important for robot safety and maintenance.

**Articulated Robot**: A robot with rotary joints (e.g., an arm), allowing for complex movements in three-dimensional space.

**Asimov's Laws of Robotics**: A set of rules devised by science fiction author Isaac Asimov to prevent robots from harming humans, though not actual laws in modern robotics.

**Assistive Robotics**: Robots designed to assist humans in daily activities, particularly important for elderly care and disability support.

**Autonomous Mobile Robot (AMR)**: A robot that can navigate and operate without human intervention, using sensors and AI to perceive and interact with its environment.

**Autonomous System**: A system that can operate independently without human intervention, making decisions based on its programming and environmental inputs.

## B

**Behavior Tree**: A hierarchical structure used in robotics and AI to organize and execute complex behaviors, providing a more flexible alternative to finite state machines.

**Biomechanics**: The study of the structure, function, and motion of the mechanical aspects of biological systems, particularly relevant for humanoid robot design.

**Biometric Recognition**: The identification of humans by their unique biological traits such as fingerprints, iris patterns, or facial features, used in robot security systems.

**Bipedal Locomotion**: Two-legged walking, a key challenge in humanoid robotics that requires complex balance and coordination algorithms.

**Black Box AI**: AI systems where the internal decision-making process is not transparent or understandable to humans, raising concerns about trust and safety.

**Braitenberg Vehicle**: A concept in robotics and artificial life of a simple agent that appears to have complex behavior based on simple rules, used to study emergent behavior.

**Brain-Computer Interface (BCI)**: A direct communication pathway between the brain and an external device, increasingly relevant for assistive robotics.

**Braitenberg Vehicle**: A concept in robotics of simple vehicles that exhibit complex behaviors through simple sensor-motor connections, used to study emergent behavior.

## C

**Canonical Robot**: A standard or typical robot configuration used as a reference in robotics research and education.

**Cartesian Space**: The three-dimensional space defined by X, Y, Z coordinates, used to describe the position and orientation of robot end-effectors.

**Causal Reasoning**: The ability to understand cause-and-effect relationships, crucial for robots to predict the outcomes of their actions.

**Cerebellar Model**: A type of neural network inspired by the structure and function of the cerebellum, used in robot control systems.

**Cognitive Architecture**: A blueprint for intelligent agents that specifies how intelligence can emerge from the interaction of simpler units, relevant for robot AI systems.

**Collaborative Robot (Cobot)**: A robot designed to work safely alongside humans in a shared workspace, with built-in safety features.

**Collision Detection**: The computational problem of detecting when two or more bodies come into contact, essential for robot safety.

**Command Governor**: A control system component that modifies reference commands to ensure constraints are satisfied, important for safe robot operation.

**Compliance Control**: A control method that allows robots to adapt their behavior based on contact forces, enabling safe interaction with humans and environments.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world, crucial for robot perception.

**Conformant Planning**: Planning under uncertainty where the initial state is not fully known, requiring plans that work for all possible initial states.

**Control Lyapunov Function**: A mathematical function used to prove the stability of control systems, important for robot stability analysis.

**Convolutional Neural Network (CNN)**: A class of deep neural networks commonly used in computer vision tasks, essential for robot perception systems.

**Cooperative Robotics**: The study and implementation of multiple robots working together to achieve common goals, requiring coordination algorithms.

**Cultural Robotics**: The study of how robots can be designed to respect and adapt to human cultural norms and practices.

## D

**D* Algorithm**: An incremental heuristic search algorithm used for path planning in unknown or dynamic environments.

**Deep Learning**: A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns, fundamental to modern robotics AI.

**Deep Reinforcement Learning**: A combination of deep learning and reinforcement learning, enabling robots to learn complex behaviors through trial and error.

**Delta Robot**: A parallel robot with three arms connected to a universal joint, used for high-speed pick-and-place operations.

**Dexterous Manipulation**: The ability to perform complex manipulation tasks requiring fine motor control, similar to human hand capabilities.

**Digital Twin**: A virtual replica of a physical robot or system that can be used for simulation, analysis, and optimization.

**Distributed Robotics**: The study of multiple robots working together as a system, where control and decision-making are distributed among the robots.

**Domain Adaptation**: The process of adapting a model trained in one domain to work effectively in a different but related domain, crucial for sim-to-real transfer.

**Domain Randomization**: A technique in simulation where environment parameters are randomized to improve the transfer of learned behaviors from simulation to reality.

**Dynamic Movement Primitives (DMP)**: A method for learning and reproducing complex movements, used in robot motor control.

**Dynamic Sim-to-Real**: The process of transferring control policies from simulation to real robots while accounting for dynamic differences.

## E

**Embodied AI**: Artificial intelligence that is integrated into physical systems, allowing for interaction with the real world through sensors and actuators.

**Embodied Cognition**: The theory that cognitive processes are deeply rooted in the body's interactions with the environment, relevant for robot design.

**End-Effector**: The device at the end of a robotic arm that interacts with the environment, such as a gripper or tool.

**Episodic Memory**: The ability to store and recall specific events and experiences, important for robots that need to learn from past interactions.

**Ethical AI**: AI systems designed and implemented with consideration for ethical principles, particularly important in autonomous robots.

**Euclidean Distance**: The "ordinary" straight-line distance between two points in Euclidean space, commonly used in robotics path planning.

**Explainable AI (XAI)**: AI systems that can explain their reasoning and decision-making processes to humans, important for trust in autonomous robots.

**Extended Kalman Filter (EKF)**: A nonlinear version of the Kalman filter used for state estimation in robotics systems.

## F

**Failure Mode and Effects Analysis (FMEA)**: A systematic approach to identifying potential failure points in robot systems and their effects.

**Fiducial Marker**: A visual marker used for robot localization and navigation, providing reference points in the environment.

**Field Robotics**: The application of robotics in unstructured outdoor environments, such as agriculture, mining, or exploration.

**Fiducial Marker**: A visual marker used for robot localization and navigation, providing reference points in the environment.

**Fuzzy Logic**: A form of many-valued logic that deals with reasoning that is approximate rather than fixed and exact, used in robot control systems.

## G

**Gaussian Process**: A non-parametric method for regression and classification, used in robotics for uncertainty quantification.

**Gazebo**: An open-source 3D robotics simulator that provides accurate physics simulation and realistic rendering.

**General-Purpose Robot**: A robot designed to perform a wide variety of tasks rather than being specialized for specific applications.

**Gesture Recognition**: The ability of robots to interpret human gestures as commands or communication, important for human-robot interaction.

**Gibson's Affordance Theory**: The theory that the environment offers possibilities for action to an organism, relevant for robot perception and interaction.

**Gradient Descent**: An optimization algorithm used to minimize functions by iteratively moving in the direction of steepest descent.

**Graph SLAM**: A form of Simultaneous Localization and Mapping that represents the problem as a graph optimization problem.

**Gripper**: A device used by robots to grasp and manipulate objects, ranging from simple pincers to complex anthropomorphic hands.

## H

**Haptic Feedback**: The use of touch and motion sensation to provide information to a user, important for teleoperation and human-robot interaction.

**Heuristic Search**: A search algorithm that uses heuristic functions to guide its search for solutions, commonly used in robot path planning.

**Hilbert Space**: A mathematical concept used in robotics for representing infinite-dimensional function spaces, relevant for robot learning.

**HRI (Human-Robot Interaction)**: The study of interactions between humans and robots, including communication, collaboration, and safety.

**Human-Centered Robotics**: The design of robots that prioritize human needs, safety, and preferences in their development and operation.

**Humanoid Robot**: A robot with a human-like body structure, typically including a head, torso, arms, and legs.

**Hybrid Systems**: Systems that exhibit both continuous and discrete dynamic behavior, common in robotics with digital controllers and analog physical systems.

## I

**Imitative Learning**: Learning by observing and replicating the behavior of others, important for robot skill acquisition.

**Impedance Control**: A control method that regulates the dynamic relationship between forces and motion, enabling robots to interact safely with environments.

**Inertial Measurement Unit (IMU)**: A device that measures and reports a body's specific force, angular rate, and sometimes magnetic field, essential for robot navigation.

**Intention Recognition**: The ability of robots to understand human intentions from observed behavior, important for collaborative robotics.

**Inverse Kinematics**: The mathematical process of determining the joint parameters needed to place a robot's end-effector at a desired position and orientation.

**Isaac ROS**: NVIDIA's collection of hardware-accelerated perception and navigation packages for ROS/ROS2.

**Isaac Sim**: NVIDIA's robotics simulation platform built on Omniverse, providing high-fidelity simulation capabilities.

## J

**Jacobian Matrix**: A matrix of partial derivatives that describes the relationship between joint velocities and end-effector velocities in robotics.

**Joint Space**: The space defined by the robot's joint angles, as opposed to Cartesian space defined by position coordinates.

**Jumping Robot**: A robot designed to move by jumping, useful for traversing obstacles and uneven terrain.

## K

**Kalman Filter**: An algorithm that uses a series of measurements observed over time to estimate unknown variables, widely used in robotics for state estimation.

**Kinematic Chain**: An assembly of rigid bodies connected by joints to provide constrained motion, fundamental to robot arm design.

**Kinesthetic Teaching**: A method of programming robots by physically guiding them through desired motions, useful for complex manipulation tasks.

## L

**Lagrangian Mechanics**: A reformulation of classical mechanics that describes the motion of systems using energy functions, used in robot dynamics.

**Laser Range Finder**: A device that measures distance by illuminating a target with a laser and analyzing the reflected light, used in robot navigation.

**Latent Space**: A lower-dimensional space that captures the essential features of high-dimensional data, used in robot learning and representation.

**Learning from Demonstration (LfD)**: A method where robots learn tasks by observing human demonstrations, important for skill transfer.

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances, crucial for robot perception.

**Localization**: The process of determining a robot's position and orientation in a known environment, essential for autonomous navigation.

**Logic Programming**: A programming paradigm based on formal logic, used in some robot reasoning systems.

## M

**Manipulability**: A measure of how easily a robot manipulator can move in different directions, important for task planning.

**Manipulation**: The ability to physically interact with objects in the environment, a fundamental capability for service robots.

**Markov Decision Process (MDP)**: A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Mental Model**: An internal representation of an external reality, important for robots to understand human intentions and expectations.

**Meta-Learning**: The ability to learn how to learn, enabling robots to quickly adapt to new tasks and environments.

**Micro-Robotics**: The field of miniature robots, typically ranging from millimeters to micrometers in size.

**Mobile Manipulator**: A robot that combines mobility and manipulation capabilities, such as a manipulator arm mounted on a mobile base.

**Model Predictive Control (MPC)**: An advanced control method that uses a model of the system to predict future behavior and optimize control actions.

**Motion Planning**: The computational problem of finding a sequence of valid configurations to move an object from a source to a destination.

## N

**Navigation Stack**: A collection of software packages that provide navigation capabilities to mobile robots, commonly used in ROS.

**Neural Radiance Fields (NeRF)**: A technique for synthesizing novel views of complex scenes using neural networks, relevant for robot perception.

**Newton-Euler Algorithm**: A recursive method for computing the inverse dynamics of a robot manipulator, important for robot control.

**Nondeterministic Environment**: An environment where the next state is not completely determined by the current state and action, requiring robots to handle uncertainty.

## O

**Occupancy Grid**: A probabilistic 2D representation of space used in robotics for mapping and navigation.

**Omnidirectional Robot**: A robot that can move in any direction without needing to turn, providing greater mobility in constrained spaces.

**Ontology**: A formal representation of knowledge in a domain, used in robotics for semantic understanding and reasoning.

**OpenRAVE**: An open-source robotics simulation environment for modeling, planning, and control research.

**Operational Space**: The space in which the robot's end-effector operates, typically Cartesian space for position and orientation.

**Oscillator**: A system that exhibits periodic behavior, used in robotics for generating rhythmic movements like walking.

## P

**Path Planning**: The computational process of finding a valid path from a start to a goal position, considering obstacles and constraints.

**Perception Stack**: The collection of sensors and algorithms that enable a robot to perceive and understand its environment.

**Physical Human-Robot Interaction (pHRI)**: Direct physical interaction between humans and robots, requiring special safety considerations.

**PID Controller**: A control loop feedback mechanism widely used in robotics for precise control of motor positions, velocities, and torques.

**Planning Domain Definition Language (PDDL)**: A formal language used to describe planning problems in robotics and AI.

**Point Cloud**: A set of data points in space, typically representing the external surface of an object, used in 3D mapping and perception.

**Poisson Process**: A mathematical model for random events occurring independently at a constant average rate, used in sensor modeling.

**Potential Field**: A method for path planning that treats the robot as a particle moving under the influence of attractive and repulsive forces.

**Probabilistic Robotics**: The study of robotics using probability theory to model uncertainty in sensing and action.

**Proportional-Integral-Derivative (PID) Control**: A control algorithm that uses proportional, integral, and derivative terms to achieve precise control.

## Q

**Quaternion**: A mathematical representation of rotation in 3D space, preferred over Euler angles for avoiding gimbal lock in robotics.

**Q-Learning**: A model-free reinforcement learning algorithm that learns a policy telling an agent what action to take under what circumstances.

## R

**RANSAC (Random Sample Consensus)**: An iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, used in computer vision.

**Reachability Analysis**: The study of which states a system can reach from a given set of initial states, important for robot safety verification.

**Reactive Robot**: A robot that responds directly to sensory input without maintaining an internal state, following simple stimulus-response rules.

**Reinforcement Learning**: A type of machine learning where agents learn to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides hardware abstraction, device drivers, and message passing.

**Robotics Middleware**: Software that provides common services and capabilities for robot applications, such as ROS and ROS2.

**ROS 2**: The second generation of the Robot Operating System, designed for production robotics applications.

**RRT (Rapidly-exploring Random Tree)**: A path planning algorithm that incrementally builds a tree of possible paths in high-dimensional spaces.

**Runge-Kutta Methods**: A family of iterative methods used for approximating solutions to ordinary differential equations, used in robot simulation.

## S

**Safety-Critical System**: A system whose failure could result in human injury or death, requiring special safety verification in robotics.

**Saliency Detection**: The process of identifying the most visually significant or relevant regions in an image, used in robot attention systems.

**Screw Theory**: A mathematical framework for describing the motion of rigid bodies, used in robot kinematics and dynamics.

**Semantic Mapping**: The process of creating maps that include semantic information about objects and places, beyond geometric information.

**Sensor Fusion**: The process of combining data from multiple sensors to achieve better accuracy and reliability than individual sensors.

**Simultaneous Localization and Mapping (SLAM)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location.

**Singularity**: A configuration of a robot manipulator where it loses one or more degrees of freedom, causing control problems.

**Social Robot**: A robot designed to interact with humans in a socially acceptable manner, often using natural communication modalities.

**State Estimation**: The process of determining the internal state of a system from noisy measurements, fundamental to robot navigation.

**State Space**: The set of all possible states of a system, used in robotics for planning and control.

**Supervised Learning**: A type of machine learning where the model is trained on labeled data, used in robot perception and control.

## T

**Task Planning**: The process of decomposing high-level goals into sequences of actions that can be executed by a robot.

**Teleoperation**: The remote operation of a robot by a human operator, often used for dangerous or inaccessible environments.

**Temporal Logic**: A system of rules and symbolism for representing and reasoning about propositions qualified in terms of time, used in robot verification.

**TensorRT**: NVIDIA's SDK for high-performance inference of deep learning models, important for edge AI in robotics.

**Tolerance Analysis**: The study of how variations in manufacturing and assembly affect robot performance, important for design.

**Trajectory Optimization**: The process of finding the optimal path for a robot to follow, considering dynamics, obstacles, and constraints.

**Trust in Automation**: The degree to which humans rely on automated systems, crucial for human-robot collaboration.

## U

**Unicycle Model**: A simplified model of wheeled robot motion that treats the robot as a unicycle for planning and control purposes.

**Uncertainty Quantification**: The process of characterizing and quantifying uncertainty in computational models, important for robust robot control.

**Universal Robot Description Format (URDF)**: An XML format for representing robot models in ROS, describing kinematics and dynamics.

**Ultrasonic Sensor**: A sensor that uses sound waves above the human hearing range to measure distances, commonly used in robotics.

## V

**Variance-Based Sensitivity Analysis**: A method for determining how much of the output variance of a model is due to each input parameter, used in robot design.

**Vector Field**: A mathematical construct that assigns a vector to each point in space, used in robot navigation and control.

**Verifiable AI**: AI systems that can be formally verified to meet certain safety or performance properties, important for robotics.

**Vision-Language-Action (VLA)**: An approach to robotics AI that integrates visual perception, language understanding, and physical action.

**Visual Servoing**: A control method that uses visual feedback to control robot motion, enabling precise positioning tasks.

## W

**Wheeled Mobile Robot**: A robot that uses wheels for locomotion, the most common type of mobile robot platform.

**Whole-Body Control**: A control approach that considers the entire robot body simultaneously, important for humanoid robots.

**Workspace**: The space in which a robot manipulator can operate, defined by the robot's physical constraints.

## X

**Xenobiotic Robotics**: The design of robots that can operate in hostile or alien environments, such as space or deep sea exploration.

## Y

**Yaw**: The rotation of a robot around its vertical axis, one of the three primary rotational movements (pitch, roll, yaw).

## Z

**Zero-Moment Point (ZMP)**: A criterion for static and dynamic stability of legged robots, important for bipedal locomotion.

**Zonotope**: A mathematical concept used in robotics for representing sets of possible states under uncertainty, important for verification.

---

Continue with [Troubleshooting Guide](./troubleshooting.md) to provide solutions for common issues encountered in robotics development and deployment.